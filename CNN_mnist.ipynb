{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Anup8777/TensorFlow_DeepLearning/blob/master/CNN_mnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WK6pVLpqK34t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "53e740ef-22c1-43c7-c9d3-221f032b3ac7"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers as layers\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorboard\n",
        "import datetime\n",
        "import warnings\n",
        "import os\n",
        "from sklearn import metrics\n",
        "\n",
        "%load_ext tensorboard"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0YuY3mSrPTSU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "logdir = os.path.join(\"logs\", datetime.datetime.now( ).strftime(\"%Y%m%d-%H%M%S\"))\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvDy2Z27Ljyu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ELRYthrCWCBw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a7865ffb-97a3-4134-d9a9-78b9d4f8378c"
      },
      "source": [
        "img_rows = x_train[0].shape[0]\n",
        "img_cols = x_test[0].shape[1]\n",
        "\n",
        "x_train = x_train.reshape(x_train.shape[0],img_rows,img_cols,1)\n",
        "x_test = x_test.reshape(x_test.shape[0],img_rows,img_cols,1)\n",
        "in_shape = (img_rows, img_cols, 1) "
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28, 28, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RnOIDcBSMrCS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "tf.keras.layers.Conv2D(filters=32, kernel_size=(2,2), strides=(1, 1), input_shape=in_shape ),\n",
        "tf.keras.layers.MaxPool2D(),\n",
        "tf.keras.layers.Flatten(),\n",
        "tf.keras.layers.Dense(10, activation='softmax')])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49xLBTNoNwr_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='Adam', loss=tf.keras.losses.sparse_categorical_crossentropy, metrics='accuracy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zedmVu_Nx6p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 128\n",
        "EPOCHS = 30"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6XuUmixN0p-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "457d1bb7-3db4-4037-c7eb-22a18d1db012"
      },
      "source": [
        "model.fit(x_train, y_train, batch_size=BATCH_SIZE, epochs = EPOCHS, verbose=1, callbacks= [tensorboard_callback], validation_split=0.8, shuffle=True )"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "94/94 [==============================] - 9s 93ms/step - loss: 4.2273 - accuracy: 0.8280 - val_loss: 1.6175 - val_accuracy: 0.8881\n",
            "Epoch 2/200\n",
            "94/94 [==============================] - 9s 91ms/step - loss: 0.8930 - accuracy: 0.9197 - val_loss: 1.1299 - val_accuracy: 0.9064\n",
            "Epoch 3/200\n",
            "94/94 [==============================] - 9s 91ms/step - loss: 0.5325 - accuracy: 0.9398 - val_loss: 0.9536 - val_accuracy: 0.9142\n",
            "Epoch 4/200\n",
            "94/94 [==============================] - 9s 90ms/step - loss: 0.3514 - accuracy: 0.9520 - val_loss: 0.8754 - val_accuracy: 0.9188\n",
            "Epoch 5/200\n",
            "94/94 [==============================] - 8s 87ms/step - loss: 0.2372 - accuracy: 0.9627 - val_loss: 0.7761 - val_accuracy: 0.9244\n",
            "Epoch 6/200\n",
            "94/94 [==============================] - 8s 86ms/step - loss: 0.1574 - accuracy: 0.9721 - val_loss: 0.7432 - val_accuracy: 0.9310\n",
            "Epoch 7/200\n",
            "94/94 [==============================] - 8s 89ms/step - loss: 0.1534 - accuracy: 0.9707 - val_loss: 0.7484 - val_accuracy: 0.9279\n",
            "Epoch 8/200\n",
            "94/94 [==============================] - 8s 88ms/step - loss: 0.1289 - accuracy: 0.9762 - val_loss: 0.7732 - val_accuracy: 0.9298\n",
            "Epoch 9/200\n",
            "94/94 [==============================] - 10s 101ms/step - loss: 0.1041 - accuracy: 0.9800 - val_loss: 0.7295 - val_accuracy: 0.9344\n",
            "Epoch 10/200\n",
            "94/94 [==============================] - 9s 92ms/step - loss: 0.0859 - accuracy: 0.9819 - val_loss: 0.7404 - val_accuracy: 0.9350\n",
            "Epoch 11/200\n",
            "94/94 [==============================] - 9s 92ms/step - loss: 0.0776 - accuracy: 0.9829 - val_loss: 0.7330 - val_accuracy: 0.9338\n",
            "Epoch 12/200\n",
            "94/94 [==============================] - 9s 92ms/step - loss: 0.0746 - accuracy: 0.9845 - val_loss: 0.7786 - val_accuracy: 0.9345\n",
            "Epoch 13/200\n",
            "94/94 [==============================] - 9s 93ms/step - loss: 0.0680 - accuracy: 0.9839 - val_loss: 0.7459 - val_accuracy: 0.9366\n",
            "Epoch 14/200\n",
            "94/94 [==============================] - 9s 93ms/step - loss: 0.0666 - accuracy: 0.9857 - val_loss: 0.7428 - val_accuracy: 0.9405\n",
            "Epoch 15/200\n",
            "94/94 [==============================] - 9s 93ms/step - loss: 0.0531 - accuracy: 0.9872 - val_loss: 0.7475 - val_accuracy: 0.9407\n",
            "Epoch 16/200\n",
            "94/94 [==============================] - 9s 96ms/step - loss: 0.0523 - accuracy: 0.9892 - val_loss: 0.7311 - val_accuracy: 0.9418\n",
            "Epoch 17/200\n",
            "94/94 [==============================] - 9s 99ms/step - loss: 0.0352 - accuracy: 0.9911 - val_loss: 0.7625 - val_accuracy: 0.9399\n",
            "Epoch 18/200\n",
            "94/94 [==============================] - 9s 97ms/step - loss: 0.0476 - accuracy: 0.9888 - val_loss: 0.8043 - val_accuracy: 0.9374\n",
            "Epoch 19/200\n",
            "94/94 [==============================] - 9s 95ms/step - loss: 0.0512 - accuracy: 0.9882 - val_loss: 0.8345 - val_accuracy: 0.9391\n",
            "Epoch 20/200\n",
            "94/94 [==============================] - 9s 92ms/step - loss: 0.0415 - accuracy: 0.9902 - val_loss: 0.8172 - val_accuracy: 0.9397\n",
            "Epoch 21/200\n",
            "94/94 [==============================] - 9s 91ms/step - loss: 0.0395 - accuracy: 0.9915 - val_loss: 0.8189 - val_accuracy: 0.9411\n",
            "Epoch 22/200\n",
            "94/94 [==============================] - 9s 91ms/step - loss: 0.0515 - accuracy: 0.9897 - val_loss: 0.8490 - val_accuracy: 0.9383\n",
            "Epoch 23/200\n",
            "94/94 [==============================] - 9s 91ms/step - loss: 0.0618 - accuracy: 0.9885 - val_loss: 0.9316 - val_accuracy: 0.9379\n",
            "Epoch 24/200\n",
            "94/94 [==============================] - 8s 90ms/step - loss: 0.0485 - accuracy: 0.9902 - val_loss: 0.9604 - val_accuracy: 0.9357\n",
            "Epoch 25/200\n",
            "94/94 [==============================] - 11s 116ms/step - loss: 0.0802 - accuracy: 0.9858 - val_loss: 0.9330 - val_accuracy: 0.9406\n",
            "Epoch 26/200\n",
            "94/94 [==============================] - 9s 94ms/step - loss: 0.0746 - accuracy: 0.9858 - val_loss: 0.9579 - val_accuracy: 0.9388\n",
            "Epoch 27/200\n",
            "94/94 [==============================] - 9s 95ms/step - loss: 0.0708 - accuracy: 0.9884 - val_loss: 0.9208 - val_accuracy: 0.9392\n",
            "Epoch 28/200\n",
            "94/94 [==============================] - 9s 96ms/step - loss: 0.0517 - accuracy: 0.9901 - val_loss: 0.9528 - val_accuracy: 0.9420\n",
            "Epoch 29/200\n",
            "94/94 [==============================] - 9s 92ms/step - loss: 0.0481 - accuracy: 0.9905 - val_loss: 0.9557 - val_accuracy: 0.9411\n",
            "Epoch 30/200\n",
            "94/94 [==============================] - 8s 90ms/step - loss: 0.0664 - accuracy: 0.9885 - val_loss: 0.9867 - val_accuracy: 0.9406\n",
            "Epoch 31/200\n",
            "94/94 [==============================] - 9s 91ms/step - loss: 0.0626 - accuracy: 0.9897 - val_loss: 0.9836 - val_accuracy: 0.9419\n",
            "Epoch 32/200\n",
            "94/94 [==============================] - 9s 91ms/step - loss: 0.0640 - accuracy: 0.9894 - val_loss: 1.0479 - val_accuracy: 0.9403\n",
            "Epoch 33/200\n",
            "94/94 [==============================] - 9s 95ms/step - loss: 0.0426 - accuracy: 0.9927 - val_loss: 1.1452 - val_accuracy: 0.9314\n",
            "Epoch 34/200\n",
            "94/94 [==============================] - 9s 94ms/step - loss: 0.0304 - accuracy: 0.9932 - val_loss: 1.0583 - val_accuracy: 0.9418\n",
            "Epoch 35/200\n",
            "94/94 [==============================] - 9s 94ms/step - loss: 0.0305 - accuracy: 0.9939 - val_loss: 1.0944 - val_accuracy: 0.9408\n",
            "Epoch 36/200\n",
            "94/94 [==============================] - 9s 95ms/step - loss: 0.0388 - accuracy: 0.9932 - val_loss: 1.0519 - val_accuracy: 0.9414\n",
            "Epoch 37/200\n",
            "94/94 [==============================] - 9s 94ms/step - loss: 0.0472 - accuracy: 0.9918 - val_loss: 1.0452 - val_accuracy: 0.9416\n",
            "Epoch 38/200\n",
            "94/94 [==============================] - 9s 92ms/step - loss: 0.0385 - accuracy: 0.9939 - val_loss: 1.0887 - val_accuracy: 0.9419\n",
            "Epoch 39/200\n",
            "94/94 [==============================] - 9s 94ms/step - loss: 0.0457 - accuracy: 0.9912 - val_loss: 1.0692 - val_accuracy: 0.9418\n",
            "Epoch 40/200\n",
            "94/94 [==============================] - 9s 100ms/step - loss: 0.0628 - accuracy: 0.9897 - val_loss: 1.0960 - val_accuracy: 0.9430\n",
            "Epoch 41/200\n",
            "94/94 [==============================] - 10s 102ms/step - loss: 0.0510 - accuracy: 0.9921 - val_loss: 1.1036 - val_accuracy: 0.9422\n",
            "Epoch 42/200\n",
            "94/94 [==============================] - 10s 103ms/step - loss: 0.0636 - accuracy: 0.9911 - val_loss: 1.1482 - val_accuracy: 0.9402\n",
            "Epoch 43/200\n",
            "94/94 [==============================] - 10s 103ms/step - loss: 0.0519 - accuracy: 0.9922 - val_loss: 1.1532 - val_accuracy: 0.9407\n",
            "Epoch 44/200\n",
            "94/94 [==============================] - 10s 102ms/step - loss: 0.0531 - accuracy: 0.9917 - val_loss: 1.3362 - val_accuracy: 0.9347\n",
            "Epoch 45/200\n",
            "94/94 [==============================] - 10s 104ms/step - loss: 0.0763 - accuracy: 0.9892 - val_loss: 1.2367 - val_accuracy: 0.9389\n",
            "Epoch 46/200\n",
            "94/94 [==============================] - 10s 102ms/step - loss: 0.0656 - accuracy: 0.9898 - val_loss: 1.1588 - val_accuracy: 0.9444\n",
            "Epoch 47/200\n",
            "94/94 [==============================] - 9s 97ms/step - loss: 0.0460 - accuracy: 0.9929 - val_loss: 1.2692 - val_accuracy: 0.9410\n",
            "Epoch 48/200\n",
            "94/94 [==============================] - 10s 104ms/step - loss: 0.0349 - accuracy: 0.9942 - val_loss: 1.1981 - val_accuracy: 0.9427\n",
            "Epoch 49/200\n",
            "94/94 [==============================] - 10s 111ms/step - loss: 0.0279 - accuracy: 0.9948 - val_loss: 1.1148 - val_accuracy: 0.9455\n",
            "Epoch 50/200\n",
            "94/94 [==============================] - 10s 103ms/step - loss: 0.0565 - accuracy: 0.9917 - val_loss: 1.3699 - val_accuracy: 0.9378\n",
            "Epoch 51/200\n",
            "94/94 [==============================] - 10s 105ms/step - loss: 0.0507 - accuracy: 0.9927 - val_loss: 1.3875 - val_accuracy: 0.9356\n",
            "Epoch 52/200\n",
            "94/94 [==============================] - 10s 101ms/step - loss: 0.0493 - accuracy: 0.9928 - val_loss: 1.2335 - val_accuracy: 0.9429\n",
            "Epoch 53/200\n",
            "94/94 [==============================] - 9s 99ms/step - loss: 0.0342 - accuracy: 0.9937 - val_loss: 1.3095 - val_accuracy: 0.9418\n",
            "Epoch 54/200\n",
            "94/94 [==============================] - 9s 100ms/step - loss: 0.0304 - accuracy: 0.9952 - val_loss: 1.3167 - val_accuracy: 0.9409\n",
            "Epoch 55/200\n",
            "94/94 [==============================] - 9s 100ms/step - loss: 0.0341 - accuracy: 0.9949 - val_loss: 1.3843 - val_accuracy: 0.9398\n",
            "Epoch 56/200\n",
            "94/94 [==============================] - 9s 99ms/step - loss: 0.0348 - accuracy: 0.9947 - val_loss: 1.2667 - val_accuracy: 0.9451\n",
            "Epoch 57/200\n",
            "94/94 [==============================] - 9s 98ms/step - loss: 0.0343 - accuracy: 0.9942 - val_loss: 1.3524 - val_accuracy: 0.9396\n",
            "Epoch 58/200\n",
            "94/94 [==============================] - 9s 98ms/step - loss: 0.0433 - accuracy: 0.9932 - val_loss: 1.3764 - val_accuracy: 0.9389\n",
            "Epoch 59/200\n",
            "94/94 [==============================] - 9s 99ms/step - loss: 0.0303 - accuracy: 0.9948 - val_loss: 1.2831 - val_accuracy: 0.9428\n",
            "Epoch 60/200\n",
            "94/94 [==============================] - 9s 98ms/step - loss: 0.0409 - accuracy: 0.9947 - val_loss: 1.4340 - val_accuracy: 0.9425\n",
            "Epoch 61/200\n",
            "94/94 [==============================] - 9s 99ms/step - loss: 0.0395 - accuracy: 0.9939 - val_loss: 1.3395 - val_accuracy: 0.9438\n",
            "Epoch 62/200\n",
            "94/94 [==============================] - 9s 98ms/step - loss: 0.0525 - accuracy: 0.9925 - val_loss: 1.5373 - val_accuracy: 0.9376\n",
            "Epoch 63/200\n",
            "94/94 [==============================] - 9s 99ms/step - loss: 0.0620 - accuracy: 0.9913 - val_loss: 1.4745 - val_accuracy: 0.9427\n",
            "Epoch 64/200\n",
            "94/94 [==============================] - 9s 100ms/step - loss: 0.0590 - accuracy: 0.9921 - val_loss: 1.3852 - val_accuracy: 0.9440\n",
            "Epoch 65/200\n",
            "94/94 [==============================] - 9s 100ms/step - loss: 0.0470 - accuracy: 0.9936 - val_loss: 1.3732 - val_accuracy: 0.9456\n",
            "Epoch 66/200\n",
            "94/94 [==============================] - 9s 100ms/step - loss: 0.0443 - accuracy: 0.9933 - val_loss: 1.3547 - val_accuracy: 0.9446\n",
            "Epoch 67/200\n",
            "94/94 [==============================] - 10s 103ms/step - loss: 0.0306 - accuracy: 0.9957 - val_loss: 1.4618 - val_accuracy: 0.9430\n",
            "Epoch 68/200\n",
            "94/94 [==============================] - 9s 100ms/step - loss: 0.0259 - accuracy: 0.9963 - val_loss: 1.3598 - val_accuracy: 0.9448\n",
            "Epoch 69/200\n",
            "94/94 [==============================] - 9s 99ms/step - loss: 0.0273 - accuracy: 0.9960 - val_loss: 1.3338 - val_accuracy: 0.9459\n",
            "Epoch 70/200\n",
            "94/94 [==============================] - 9s 99ms/step - loss: 0.0172 - accuracy: 0.9971 - val_loss: 1.3593 - val_accuracy: 0.9469\n",
            "Epoch 71/200\n",
            "94/94 [==============================] - 9s 101ms/step - loss: 0.0327 - accuracy: 0.9957 - val_loss: 1.4627 - val_accuracy: 0.9429\n",
            "Epoch 72/200\n",
            "94/94 [==============================] - 10s 101ms/step - loss: 0.0259 - accuracy: 0.9965 - val_loss: 1.4310 - val_accuracy: 0.9447\n",
            "Epoch 73/200\n",
            "94/94 [==============================] - 10s 102ms/step - loss: 0.0170 - accuracy: 0.9970 - val_loss: 1.4996 - val_accuracy: 0.9448\n",
            "Epoch 74/200\n",
            "94/94 [==============================] - 10s 102ms/step - loss: 0.0249 - accuracy: 0.9959 - val_loss: 1.5743 - val_accuracy: 0.9411\n",
            "Epoch 75/200\n",
            "94/94 [==============================] - 10s 102ms/step - loss: 0.0468 - accuracy: 0.9942 - val_loss: 1.5800 - val_accuracy: 0.9423\n",
            "Epoch 76/200\n",
            "94/94 [==============================] - 9s 101ms/step - loss: 0.0504 - accuracy: 0.9947 - val_loss: 1.6220 - val_accuracy: 0.9398\n",
            "Epoch 77/200\n",
            "94/94 [==============================] - 10s 102ms/step - loss: 0.0365 - accuracy: 0.9954 - val_loss: 1.6081 - val_accuracy: 0.9391\n",
            "Epoch 78/200\n",
            "94/94 [==============================] - 10s 104ms/step - loss: 0.0377 - accuracy: 0.9942 - val_loss: 1.5682 - val_accuracy: 0.9438\n",
            "Epoch 79/200\n",
            "94/94 [==============================] - 10s 105ms/step - loss: 0.0779 - accuracy: 0.9917 - val_loss: 1.7441 - val_accuracy: 0.9387\n",
            "Epoch 80/200\n",
            "94/94 [==============================] - 10s 103ms/step - loss: 0.0688 - accuracy: 0.9927 - val_loss: 1.5829 - val_accuracy: 0.9439\n",
            "Epoch 81/200\n",
            "94/94 [==============================] - 10s 104ms/step - loss: 0.0510 - accuracy: 0.9938 - val_loss: 1.6068 - val_accuracy: 0.9425\n",
            "Epoch 82/200\n",
            "94/94 [==============================] - 10s 106ms/step - loss: 0.0359 - accuracy: 0.9952 - val_loss: 1.7537 - val_accuracy: 0.9418\n",
            "Epoch 83/200\n",
            "94/94 [==============================] - 10s 105ms/step - loss: 0.0341 - accuracy: 0.9955 - val_loss: 1.5703 - val_accuracy: 0.9464\n",
            "Epoch 84/200\n",
            "94/94 [==============================] - 10s 107ms/step - loss: 0.0152 - accuracy: 0.9976 - val_loss: 1.5965 - val_accuracy: 0.9454\n",
            "Epoch 85/200\n",
            "94/94 [==============================] - 10s 105ms/step - loss: 0.0333 - accuracy: 0.9962 - val_loss: 1.5918 - val_accuracy: 0.9458\n",
            "Epoch 86/200\n",
            "94/94 [==============================] - 10s 102ms/step - loss: 0.0208 - accuracy: 0.9977 - val_loss: 1.5067 - val_accuracy: 0.9461\n",
            "Epoch 87/200\n",
            "94/94 [==============================] - 9s 101ms/step - loss: 0.0119 - accuracy: 0.9984 - val_loss: 1.5671 - val_accuracy: 0.9466\n",
            "Epoch 88/200\n",
            "94/94 [==============================] - 9s 100ms/step - loss: 0.0079 - accuracy: 0.9987 - val_loss: 1.5608 - val_accuracy: 0.9477\n",
            "Epoch 89/200\n",
            "94/94 [==============================] - 10s 112ms/step - loss: 0.0285 - accuracy: 0.9959 - val_loss: 1.7699 - val_accuracy: 0.9425\n",
            "Epoch 90/200\n",
            "94/94 [==============================] - 11s 113ms/step - loss: 0.0250 - accuracy: 0.9964 - val_loss: 1.6053 - val_accuracy: 0.9447\n",
            "Epoch 91/200\n",
            "94/94 [==============================] - 9s 100ms/step - loss: 0.0183 - accuracy: 0.9967 - val_loss: 1.7012 - val_accuracy: 0.9439\n",
            "Epoch 92/200\n",
            "94/94 [==============================] - 9s 101ms/step - loss: 0.0469 - accuracy: 0.9945 - val_loss: 1.7679 - val_accuracy: 0.9429\n",
            "Epoch 93/200\n",
            "94/94 [==============================] - 9s 100ms/step - loss: 0.0605 - accuracy: 0.9927 - val_loss: 1.8920 - val_accuracy: 0.9417\n",
            "Epoch 94/200\n",
            "94/94 [==============================] - 9s 100ms/step - loss: 0.0452 - accuracy: 0.9949 - val_loss: 1.7366 - val_accuracy: 0.9437\n",
            "Epoch 95/200\n",
            "94/94 [==============================] - 9s 100ms/step - loss: 0.0353 - accuracy: 0.9960 - val_loss: 1.7226 - val_accuracy: 0.9452\n",
            "Epoch 96/200\n",
            "94/94 [==============================] - 9s 99ms/step - loss: 0.0290 - accuracy: 0.9956 - val_loss: 1.7485 - val_accuracy: 0.9450\n",
            "Epoch 97/200\n",
            "94/94 [==============================] - 10s 109ms/step - loss: 0.0524 - accuracy: 0.9953 - val_loss: 1.7440 - val_accuracy: 0.9434\n",
            "Epoch 98/200\n",
            "94/94 [==============================] - 10s 103ms/step - loss: 0.0388 - accuracy: 0.9958 - val_loss: 1.8253 - val_accuracy: 0.9443\n",
            "Epoch 99/200\n",
            "94/94 [==============================] - 10s 101ms/step - loss: 0.0430 - accuracy: 0.9948 - val_loss: 1.8283 - val_accuracy: 0.9444\n",
            "Epoch 100/200\n",
            "94/94 [==============================] - 10s 104ms/step - loss: 0.0165 - accuracy: 0.9974 - val_loss: 1.7337 - val_accuracy: 0.9466\n",
            "Epoch 101/200\n",
            "94/94 [==============================] - 10s 103ms/step - loss: 0.0161 - accuracy: 0.9979 - val_loss: 1.8406 - val_accuracy: 0.9416\n",
            "Epoch 102/200\n",
            "94/94 [==============================] - 10s 103ms/step - loss: 0.0111 - accuracy: 0.9981 - val_loss: 1.8064 - val_accuracy: 0.9438\n",
            "Epoch 103/200\n",
            "94/94 [==============================] - 10s 101ms/step - loss: 0.0217 - accuracy: 0.9975 - val_loss: 1.7722 - val_accuracy: 0.9463\n",
            "Epoch 104/200\n",
            "94/94 [==============================] - 10s 102ms/step - loss: 0.0138 - accuracy: 0.9977 - val_loss: 1.7842 - val_accuracy: 0.9485\n",
            "Epoch 105/200\n",
            "94/94 [==============================] - 10s 103ms/step - loss: 0.0253 - accuracy: 0.9967 - val_loss: 1.8584 - val_accuracy: 0.9458\n",
            "Epoch 106/200\n",
            "94/94 [==============================] - 10s 105ms/step - loss: 0.0285 - accuracy: 0.9968 - val_loss: 1.8950 - val_accuracy: 0.9422\n",
            "Epoch 107/200\n",
            "94/94 [==============================] - 10s 102ms/step - loss: 0.0180 - accuracy: 0.9982 - val_loss: 1.9652 - val_accuracy: 0.9391\n",
            "Epoch 108/200\n",
            "94/94 [==============================] - 10s 103ms/step - loss: 0.0223 - accuracy: 0.9974 - val_loss: 1.9325 - val_accuracy: 0.9422\n",
            "Epoch 109/200\n",
            "94/94 [==============================] - 10s 104ms/step - loss: 0.0290 - accuracy: 0.9967 - val_loss: 2.0921 - val_accuracy: 0.9386\n",
            "Epoch 110/200\n",
            "94/94 [==============================] - 10s 105ms/step - loss: 0.0740 - accuracy: 0.9934 - val_loss: 1.9444 - val_accuracy: 0.9424\n",
            "Epoch 111/200\n",
            "94/94 [==============================] - 10s 106ms/step - loss: 0.0557 - accuracy: 0.9947 - val_loss: 2.0379 - val_accuracy: 0.9429\n",
            "Epoch 112/200\n",
            "94/94 [==============================] - 10s 105ms/step - loss: 0.0529 - accuracy: 0.9947 - val_loss: 2.1015 - val_accuracy: 0.9410\n",
            "Epoch 113/200\n",
            "94/94 [==============================] - 10s 106ms/step - loss: 0.0594 - accuracy: 0.9938 - val_loss: 2.0063 - val_accuracy: 0.9447\n",
            "Epoch 114/200\n",
            "94/94 [==============================] - 10s 104ms/step - loss: 0.0275 - accuracy: 0.9964 - val_loss: 1.9901 - val_accuracy: 0.9447\n",
            "Epoch 115/200\n",
            "94/94 [==============================] - 10s 105ms/step - loss: 0.0138 - accuracy: 0.9982 - val_loss: 1.8964 - val_accuracy: 0.9470\n",
            "Epoch 116/200\n",
            "94/94 [==============================] - 10s 105ms/step - loss: 0.0018 - accuracy: 0.9996 - val_loss: 1.9038 - val_accuracy: 0.9475\n",
            "Epoch 117/200\n",
            "94/94 [==============================] - 10s 104ms/step - loss: 0.0027 - accuracy: 0.9995 - val_loss: 1.9484 - val_accuracy: 0.9459\n",
            "Epoch 118/200\n",
            "94/94 [==============================] - 10s 104ms/step - loss: 0.0041 - accuracy: 0.9993 - val_loss: 1.8804 - val_accuracy: 0.9481\n",
            "Epoch 119/200\n",
            "94/94 [==============================] - 10s 104ms/step - loss: 0.0020 - accuracy: 0.9997 - val_loss: 1.9305 - val_accuracy: 0.9465\n",
            "Epoch 120/200\n",
            "94/94 [==============================] - 10s 105ms/step - loss: 0.0049 - accuracy: 0.9989 - val_loss: 2.0195 - val_accuracy: 0.9465\n",
            "Epoch 121/200\n",
            "94/94 [==============================] - 10s 105ms/step - loss: 0.0075 - accuracy: 0.9988 - val_loss: 1.9282 - val_accuracy: 0.9458\n",
            "Epoch 122/200\n",
            "94/94 [==============================] - 10s 105ms/step - loss: 0.0503 - accuracy: 0.9954 - val_loss: 2.2885 - val_accuracy: 0.9412\n",
            "Epoch 123/200\n",
            "94/94 [==============================] - 10s 105ms/step - loss: 0.0639 - accuracy: 0.9935 - val_loss: 2.0996 - val_accuracy: 0.9434\n",
            "Epoch 124/200\n",
            "94/94 [==============================] - 10s 103ms/step - loss: 0.0829 - accuracy: 0.9922 - val_loss: 2.3787 - val_accuracy: 0.9414\n",
            "Epoch 125/200\n",
            "94/94 [==============================] - 10s 105ms/step - loss: 0.0566 - accuracy: 0.9953 - val_loss: 2.0542 - val_accuracy: 0.9441\n",
            "Epoch 126/200\n",
            "94/94 [==============================] - 10s 103ms/step - loss: 0.0588 - accuracy: 0.9947 - val_loss: 2.2071 - val_accuracy: 0.9418\n",
            "Epoch 127/200\n",
            "94/94 [==============================] - 10s 104ms/step - loss: 0.0271 - accuracy: 0.9976 - val_loss: 2.1715 - val_accuracy: 0.9438\n",
            "Epoch 128/200\n",
            "94/94 [==============================] - 10s 105ms/step - loss: 0.0175 - accuracy: 0.9983 - val_loss: 2.2352 - val_accuracy: 0.9440\n",
            "Epoch 129/200\n",
            "94/94 [==============================] - 10s 106ms/step - loss: 0.0177 - accuracy: 0.9976 - val_loss: 2.2338 - val_accuracy: 0.9405\n",
            "Epoch 130/200\n",
            "94/94 [==============================] - 10s 108ms/step - loss: 0.0280 - accuracy: 0.9970 - val_loss: 2.1758 - val_accuracy: 0.9425\n",
            "Epoch 131/200\n",
            "94/94 [==============================] - 10s 109ms/step - loss: 0.0062 - accuracy: 0.9983 - val_loss: 2.1280 - val_accuracy: 0.9448\n",
            "Epoch 132/200\n",
            "94/94 [==============================] - 10s 104ms/step - loss: 0.0140 - accuracy: 0.9977 - val_loss: 2.1884 - val_accuracy: 0.9422\n",
            "Epoch 133/200\n",
            "94/94 [==============================] - 10s 103ms/step - loss: 0.0163 - accuracy: 0.9977 - val_loss: 2.1709 - val_accuracy: 0.9453\n",
            "Epoch 134/200\n",
            "94/94 [==============================] - 10s 104ms/step - loss: 0.0236 - accuracy: 0.9977 - val_loss: 2.1817 - val_accuracy: 0.9414\n",
            "Epoch 135/200\n",
            "94/94 [==============================] - 9s 97ms/step - loss: 0.0266 - accuracy: 0.9968 - val_loss: 2.5425 - val_accuracy: 0.9336\n",
            "Epoch 136/200\n",
            "94/94 [==============================] - 9s 94ms/step - loss: 0.0623 - accuracy: 0.9942 - val_loss: 2.3440 - val_accuracy: 0.9404\n",
            "Epoch 137/200\n",
            "94/94 [==============================] - 9s 95ms/step - loss: 0.0464 - accuracy: 0.9953 - val_loss: 2.1539 - val_accuracy: 0.9457\n",
            "Epoch 138/200\n",
            "94/94 [==============================] - 9s 97ms/step - loss: 0.0374 - accuracy: 0.9971 - val_loss: 2.4328 - val_accuracy: 0.9422\n",
            "Epoch 139/200\n",
            "94/94 [==============================] - 9s 97ms/step - loss: 0.0280 - accuracy: 0.9970 - val_loss: 2.4306 - val_accuracy: 0.9410\n",
            "Epoch 140/200\n",
            "94/94 [==============================] - 9s 97ms/step - loss: 0.0378 - accuracy: 0.9968 - val_loss: 2.3268 - val_accuracy: 0.9448\n",
            "Epoch 141/200\n",
            "94/94 [==============================] - 9s 93ms/step - loss: 0.0387 - accuracy: 0.9967 - val_loss: 2.1735 - val_accuracy: 0.9448\n",
            "Epoch 142/200\n",
            "94/94 [==============================] - 9s 93ms/step - loss: 0.0195 - accuracy: 0.9975 - val_loss: 2.3511 - val_accuracy: 0.9450\n",
            "Epoch 143/200\n",
            "94/94 [==============================] - 9s 94ms/step - loss: 0.0209 - accuracy: 0.9975 - val_loss: 2.3204 - val_accuracy: 0.9428\n",
            "Epoch 144/200\n",
            "94/94 [==============================] - 9s 92ms/step - loss: 0.0165 - accuracy: 0.9979 - val_loss: 2.3541 - val_accuracy: 0.9443\n",
            "Epoch 145/200\n",
            "94/94 [==============================] - 9s 92ms/step - loss: 0.0150 - accuracy: 0.9977 - val_loss: 2.4543 - val_accuracy: 0.9438\n",
            "Epoch 146/200\n",
            "94/94 [==============================] - 9s 92ms/step - loss: 0.0320 - accuracy: 0.9971 - val_loss: 2.4842 - val_accuracy: 0.9431\n",
            "Epoch 147/200\n",
            "94/94 [==============================] - 9s 92ms/step - loss: 0.0189 - accuracy: 0.9973 - val_loss: 2.5410 - val_accuracy: 0.9402\n",
            "Epoch 148/200\n",
            "94/94 [==============================] - 9s 95ms/step - loss: 0.0101 - accuracy: 0.9984 - val_loss: 2.4365 - val_accuracy: 0.9476\n",
            "Epoch 149/200\n",
            "94/94 [==============================] - 9s 94ms/step - loss: 0.0091 - accuracy: 0.9981 - val_loss: 2.3794 - val_accuracy: 0.9475\n",
            "Epoch 150/200\n",
            "94/94 [==============================] - 9s 93ms/step - loss: 0.0161 - accuracy: 0.9981 - val_loss: 2.3486 - val_accuracy: 0.9481\n",
            "Epoch 151/200\n",
            "94/94 [==============================] - 9s 94ms/step - loss: 0.0129 - accuracy: 0.9984 - val_loss: 2.3296 - val_accuracy: 0.9483\n",
            "Epoch 152/200\n",
            "94/94 [==============================] - 9s 94ms/step - loss: 0.0135 - accuracy: 0.9987 - val_loss: 2.4450 - val_accuracy: 0.9434\n",
            "Epoch 153/200\n",
            "94/94 [==============================] - 11s 120ms/step - loss: 0.0072 - accuracy: 0.9988 - val_loss: 2.4126 - val_accuracy: 0.9453\n",
            "Epoch 154/200\n",
            "94/94 [==============================] - 9s 94ms/step - loss: 0.0322 - accuracy: 0.9975 - val_loss: 2.6894 - val_accuracy: 0.9402\n",
            "Epoch 155/200\n",
            "94/94 [==============================] - 9s 95ms/step - loss: 0.0408 - accuracy: 0.9962 - val_loss: 2.6289 - val_accuracy: 0.9419\n",
            "Epoch 156/200\n",
            "94/94 [==============================] - 9s 96ms/step - loss: 0.0298 - accuracy: 0.9972 - val_loss: 2.4390 - val_accuracy: 0.9473\n",
            "Epoch 157/200\n",
            "94/94 [==============================] - 9s 92ms/step - loss: 0.0091 - accuracy: 0.9991 - val_loss: 2.4611 - val_accuracy: 0.9481\n",
            "Epoch 158/200\n",
            "94/94 [==============================] - 9s 92ms/step - loss: 0.0138 - accuracy: 0.9985 - val_loss: 2.6630 - val_accuracy: 0.9441\n",
            "Epoch 159/200\n",
            "94/94 [==============================] - 9s 92ms/step - loss: 0.0259 - accuracy: 0.9972 - val_loss: 2.9516 - val_accuracy: 0.9404\n",
            "Epoch 160/200\n",
            "94/94 [==============================] - 9s 91ms/step - loss: 0.0155 - accuracy: 0.9983 - val_loss: 2.5722 - val_accuracy: 0.9462\n",
            "Epoch 161/200\n",
            "94/94 [==============================] - 9s 91ms/step - loss: 0.0238 - accuracy: 0.9972 - val_loss: 2.7766 - val_accuracy: 0.9427\n",
            "Epoch 162/200\n",
            "94/94 [==============================] - 9s 94ms/step - loss: 0.0295 - accuracy: 0.9979 - val_loss: 2.5695 - val_accuracy: 0.9422\n",
            "Epoch 163/200\n",
            "94/94 [==============================] - 9s 94ms/step - loss: 0.0243 - accuracy: 0.9978 - val_loss: 2.5107 - val_accuracy: 0.9479\n",
            "Epoch 164/200\n",
            "94/94 [==============================] - 9s 94ms/step - loss: 0.0126 - accuracy: 0.9987 - val_loss: 2.7235 - val_accuracy: 0.9396\n",
            "Epoch 165/200\n",
            "94/94 [==============================] - 9s 97ms/step - loss: 0.0247 - accuracy: 0.9978 - val_loss: 2.5389 - val_accuracy: 0.9453\n",
            "Epoch 166/200\n",
            "94/94 [==============================] - 9s 94ms/step - loss: 0.0119 - accuracy: 0.9984 - val_loss: 2.7830 - val_accuracy: 0.9411\n",
            "Epoch 167/200\n",
            "94/94 [==============================] - 9s 94ms/step - loss: 0.0223 - accuracy: 0.9978 - val_loss: 2.9399 - val_accuracy: 0.9417\n",
            "Epoch 168/200\n",
            "94/94 [==============================] - 9s 97ms/step - loss: 0.0299 - accuracy: 0.9970 - val_loss: 2.8048 - val_accuracy: 0.9439\n",
            "Epoch 169/200\n",
            "94/94 [==============================] - 9s 94ms/step - loss: 0.0485 - accuracy: 0.9968 - val_loss: 2.6821 - val_accuracy: 0.9456\n",
            "Epoch 170/200\n",
            "94/94 [==============================] - 9s 96ms/step - loss: 0.0442 - accuracy: 0.9965 - val_loss: 2.7494 - val_accuracy: 0.9445\n",
            "Epoch 171/200\n",
            "94/94 [==============================] - 9s 94ms/step - loss: 0.0483 - accuracy: 0.9960 - val_loss: 2.9922 - val_accuracy: 0.9395\n",
            "Epoch 172/200\n",
            "94/94 [==============================] - 9s 94ms/step - loss: 0.0460 - accuracy: 0.9961 - val_loss: 2.7958 - val_accuracy: 0.9445\n",
            "Epoch 173/200\n",
            "94/94 [==============================] - 9s 99ms/step - loss: 0.0214 - accuracy: 0.9980 - val_loss: 2.6485 - val_accuracy: 0.9445\n",
            "Epoch 174/200\n",
            "94/94 [==============================] - 9s 100ms/step - loss: 0.0260 - accuracy: 0.9972 - val_loss: 2.8356 - val_accuracy: 0.9454\n",
            "Epoch 175/200\n",
            "94/94 [==============================] - 9s 99ms/step - loss: 0.0325 - accuracy: 0.9975 - val_loss: 2.9532 - val_accuracy: 0.9424\n",
            "Epoch 176/200\n",
            "94/94 [==============================] - 9s 93ms/step - loss: 0.0397 - accuracy: 0.9967 - val_loss: 2.7926 - val_accuracy: 0.9461\n",
            "Epoch 177/200\n",
            "94/94 [==============================] - 9s 93ms/step - loss: 0.0085 - accuracy: 0.9990 - val_loss: 2.7632 - val_accuracy: 0.9458\n",
            "Epoch 178/200\n",
            "94/94 [==============================] - 9s 94ms/step - loss: 0.0144 - accuracy: 0.9991 - val_loss: 2.9158 - val_accuracy: 0.9465\n",
            "Epoch 179/200\n",
            "94/94 [==============================] - 9s 96ms/step - loss: 0.0098 - accuracy: 0.9991 - val_loss: 3.0151 - val_accuracy: 0.9415\n",
            "Epoch 180/200\n",
            "94/94 [==============================] - 10s 105ms/step - loss: 0.0135 - accuracy: 0.9984 - val_loss: 2.7055 - val_accuracy: 0.9454\n",
            "Epoch 181/200\n",
            "94/94 [==============================] - 10s 104ms/step - loss: 0.0118 - accuracy: 0.9987 - val_loss: 2.7922 - val_accuracy: 0.9470\n",
            "Epoch 182/200\n",
            "94/94 [==============================] - 10s 106ms/step - loss: 0.0113 - accuracy: 0.9986 - val_loss: 2.9060 - val_accuracy: 0.9447\n",
            "Epoch 183/200\n",
            "94/94 [==============================] - 10s 107ms/step - loss: 0.0143 - accuracy: 0.9985 - val_loss: 2.9243 - val_accuracy: 0.9453\n",
            "Epoch 184/200\n",
            "94/94 [==============================] - 10s 104ms/step - loss: 0.0204 - accuracy: 0.9982 - val_loss: 2.8708 - val_accuracy: 0.9453\n",
            "Epoch 185/200\n",
            "94/94 [==============================] - 10s 104ms/step - loss: 0.0222 - accuracy: 0.9977 - val_loss: 2.7987 - val_accuracy: 0.9467\n",
            "Epoch 186/200\n",
            "94/94 [==============================] - 10s 102ms/step - loss: 0.0204 - accuracy: 0.9980 - val_loss: 3.1633 - val_accuracy: 0.9401\n",
            "Epoch 187/200\n",
            "94/94 [==============================] - 9s 101ms/step - loss: 0.0188 - accuracy: 0.9983 - val_loss: 3.1675 - val_accuracy: 0.9380\n",
            "Epoch 188/200\n",
            "94/94 [==============================] - 9s 100ms/step - loss: 0.0432 - accuracy: 0.9972 - val_loss: 3.0481 - val_accuracy: 0.9445\n",
            "Epoch 189/200\n",
            "94/94 [==============================] - 9s 100ms/step - loss: 0.0249 - accuracy: 0.9978 - val_loss: 2.9665 - val_accuracy: 0.9447\n",
            "Epoch 190/200\n",
            "94/94 [==============================] - 9s 101ms/step - loss: 0.0254 - accuracy: 0.9974 - val_loss: 3.0474 - val_accuracy: 0.9452\n",
            "Epoch 191/200\n",
            "94/94 [==============================] - 10s 102ms/step - loss: 0.0288 - accuracy: 0.9973 - val_loss: 2.8574 - val_accuracy: 0.9464\n",
            "Epoch 192/200\n",
            "94/94 [==============================] - 10s 105ms/step - loss: 0.0279 - accuracy: 0.9975 - val_loss: 3.0401 - val_accuracy: 0.9455\n",
            "Epoch 193/200\n",
            "94/94 [==============================] - 10s 106ms/step - loss: 0.0349 - accuracy: 0.9977 - val_loss: 3.0959 - val_accuracy: 0.9454\n",
            "Epoch 194/200\n",
            "94/94 [==============================] - 9s 95ms/step - loss: 0.0407 - accuracy: 0.9970 - val_loss: 3.1768 - val_accuracy: 0.9424\n",
            "Epoch 195/200\n",
            "94/94 [==============================] - 9s 94ms/step - loss: 0.0150 - accuracy: 0.9987 - val_loss: 2.8708 - val_accuracy: 0.9487\n",
            "Epoch 196/200\n",
            "94/94 [==============================] - 9s 94ms/step - loss: 0.0076 - accuracy: 0.9991 - val_loss: 3.0242 - val_accuracy: 0.9465\n",
            "Epoch 197/200\n",
            "94/94 [==============================] - 9s 96ms/step - loss: 0.0072 - accuracy: 0.9991 - val_loss: 2.9108 - val_accuracy: 0.9471\n",
            "Epoch 198/200\n",
            "94/94 [==============================] - 9s 95ms/step - loss: 0.0163 - accuracy: 0.9985 - val_loss: 3.1967 - val_accuracy: 0.9437\n",
            "Epoch 199/200\n",
            "94/94 [==============================] - 9s 94ms/step - loss: 0.0276 - accuracy: 0.9974 - val_loss: 3.1320 - val_accuracy: 0.9456\n",
            "Epoch 200/200\n",
            "94/94 [==============================] - 9s 93ms/step - loss: 0.0122 - accuracy: 0.9985 - val_loss: 3.0780 - val_accuracy: 0.9465\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fdc9861ff60>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ei1uEBlqP0b4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "1e5e124f-b020-4055-c26f-908c2f8739ec"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_13 (Conv2D)           (None, 27, 27, 32)        160       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_13 (MaxPooling (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "flatten_13 (Flatten)         (None, 5408)              0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 10)                54090     \n",
            "=================================================================\n",
            "Total params: 54,250\n",
            "Trainable params: 54,250\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQNR8dxFioTo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_hat = model.predict(x_test, batch_size=32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhl86zO0i0B0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "07d477c6-6332-4823-9c8d-59098c881fb9"
      },
      "source": [
        "model.evaluate(x_test, y_test)"
      ],
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 2s 6ms/step - loss: 2.9926 - accuracy: 0.9507\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.9925537109375, 0.9506999850273132]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yHFUOgwjL3e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "cc594821-19b9-4b9f-d479-c61d8811e82d"
      },
      "source": [
        "sns.heatmap(tf.math.confusion_matrix(y_hat.argmax(axis=1), y_test ), cmap='Blues_r')"
      ],
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fdc9026cac8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 156
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjjwPXQEjdyi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "e60a6702-5b1a-4f83-81b4-f2e884a1deda"
      },
      "source": [
        "tf.math.confusion_matrix(y_hat.argmax(axis=1), y_test )"
      ],
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10, 10), dtype=int32, numpy=\n",
              "array([[ 955,    3,    1,    1,    1,    3,   10,    0,    3,    6],\n",
              "       [   0, 1121,   14,    1,    3,    3,    3,    9,    6,    5],\n",
              "       [   3,    3,  972,   14,    4,    2,    5,   20,    7,    1],\n",
              "       [   1,    4,    8,  955,    1,   11,    0,   10,   22,    2],\n",
              "       [   1,    0,    8,    2,  941,    2,    7,    4,    7,   10],\n",
              "       [   5,    1,    1,   17,    0,  852,   11,    0,   18,    9],\n",
              "       [   6,    0,    3,    1,    3,    9,  914,    0,    2,    0],\n",
              "       [   2,    1,   10,    7,    3,    4,    1,  967,   14,   16],\n",
              "       [   7,    2,    9,    5,    4,    3,    5,    4,  878,    8],\n",
              "       [   0,    0,    6,    7,   22,    3,    2,   14,   17,  952]],\n",
              "      dtype=int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlLfLQS3lH0E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "outputId": "188d144e-2fce-440a-e2b7-12e745bab646"
      },
      "source": [
        "print(metrics.classification_report(y_hat.argmax(axis=1), y_test))"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.97      0.97       983\n",
            "           1       0.99      0.96      0.97      1165\n",
            "           2       0.94      0.94      0.94      1031\n",
            "           3       0.95      0.94      0.94      1014\n",
            "           4       0.96      0.96      0.96       982\n",
            "           5       0.96      0.93      0.94       914\n",
            "           6       0.95      0.97      0.96       938\n",
            "           7       0.94      0.94      0.94      1025\n",
            "           8       0.90      0.95      0.92       925\n",
            "           9       0.94      0.93      0.94      1023\n",
            "\n",
            "    accuracy                           0.95     10000\n",
            "   macro avg       0.95      0.95      0.95     10000\n",
            "weighted avg       0.95      0.95      0.95     10000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZN0cOT75lSAJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "outputId": "906b0b90-667d-4e97-b9a9-55507750bb80"
      },
      "source": [
        "plt.hist((y_hat.argmax(axis=1) - y_test))"
      ],
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([  14.,   35.,   93.,   28.,  109., 9551.,   58.,   30.,   65.,\n",
              "          17.]),\n",
              " array([-9. , -7.3, -5.6, -3.9, -2.2, -0.5,  1.2,  2.9,  4.6,  6.3,  8. ]),\n",
              " <a list of 10 Patch objects>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 154
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmFRraHslnk5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HsV2p6-Hl6Wa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}