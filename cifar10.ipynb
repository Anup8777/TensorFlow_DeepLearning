{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1PEvTjY2I5ZUHJiczMBTsFmxhihznIdXk",
      "authorship_tag": "ABX9TyPmE1yNazzZ00F9jFPLhu64",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Anup8777/TensorFlow_DeepLearning/blob/master/cifar10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IR-ydQSO45Ri",
        "colab_type": "text"
      },
      "source": [
        "# Convolutional Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S4Zlx57u5BMM",
        "colab_type": "text"
      },
      "source": [
        "## CNN for MNIST dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5PbM7SWV5SMe",
        "colab_type": "text"
      },
      "source": [
        "The MNIST dataset is not a complecated dataset with images of RGB values. It does not require a super deep or a deep CNN for classification of digits. The simple CNN with one layer 32 filters of stride 2 with Relu activation and one output layer with a Softmax activation gives us a descent accuracy. \n",
        "\n",
        "The filters, the filter layers, the stride and the pooling size are the some of the very important factors that affect the performance of the CNN. However, this does not mean that the other factors do not play an important role.\n",
        "\n",
        "The filters and the pooling layers play a more prominent role than the non linear layers in the CNN, which is unlike in MLPs or Feed Forward Networks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vy-W36Br41Rl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "6f239a14-f08f-4ba7-9982-45616cf17e5a"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers as layers\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorboard\n",
        "import datetime\n",
        "import warnings\n",
        "import os\n",
        "from sklearn import metrics\n",
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.layers import Dense, Conv2D, BatchNormalization, Activation\n",
        "from keras.layers import AveragePooling2D, Input, Flatten\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.regularizers import l2\n",
        "from keras import backend as K\n",
        "from keras.models import Model\n",
        "from keras.datasets import cifar10, cifar100\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "%load_ext tensorboard"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n",
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qiNGLAwx8EVe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "logdir = os.path.join(\"logs\", datetime.datetime.now( ).strftime(\"%Y%m%d-%H%M%S\"))\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAYkFd0b8In6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "54cb3a76-36e6-457a-db2b-484847e69e8f"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "img_rows = x_train[0].shape[0]\n",
        "img_cols = x_test[0].shape[1]\n",
        "no_channels = 1\n",
        "BATCH_SIZE = 128\n",
        "EPOCHS = 30\n",
        "\n",
        "x_train = x_train.reshape(x_train.shape[0],img_rows,img_cols,no_channels)\n",
        "x_test = x_test.reshape(x_test.shape[0],img_rows,img_cols,no_channels)\n",
        "in_shape = (img_rows, img_cols, no_channels)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8XBhZtZ8ljo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "tf.keras.layers.Conv2D(filters=32, kernel_size=(2,2), strides=(2, 2), input_shape=in_shape, activation='relu', kernel_initializer='he_uniform', padding='same'),\n",
        "tf.keras.layers.MaxPool2D(),\n",
        "tf.keras.layers.Flatten(),\n",
        "tf.keras.layers.Dense(10, activation='softmax')])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0W3oRZI48sxh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fc275035-b5a3-46b3-e09c-6befdb7873da"
      },
      "source": [
        "model.compile(optimizer='Adam', loss=tf.keras.losses.sparse_categorical_crossentropy, metrics='accuracy')\n",
        "model.fit(x_train, y_train, batch_size=BATCH_SIZE, epochs = EPOCHS, verbose=0, callbacks= [tensorboard_callback], validation_split=0.8, shuffle=True )"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f9cb0105e48>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5AnHOBS8xQx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3820a899-72fe-4fdb-ff52-daf30e365222"
      },
      "source": [
        "model.evaluate(x_test, y_test)\n",
        "y_hat = model.predict(x_test, batch_size=32)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 4.5972 - accuracy: 0.9261\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fV6gfhnu9Q5N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "1bf0c169-d1b4-4bff-a98e-95add5d13f32"
      },
      "source": [
        "sns.heatmap(tf.math.confusion_matrix(y_test, y_hat.argmax(axis=1)  ), cmap='GnBu', cbar=True)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f9c5a17c3c8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjXoYUp09Ba9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "outputId": "3aeac4d4-b43c-4f45-9167-dfcb855f82d3"
      },
      "source": [
        "print(metrics.classification_report( y_test, y_hat.argmax(axis=1)))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.98      0.96       980\n",
            "           1       0.99      0.94      0.97      1135\n",
            "           2       0.87      0.95      0.91      1032\n",
            "           3       0.96      0.88      0.92      1010\n",
            "           4       0.94      0.96      0.95       982\n",
            "           5       0.81      0.97      0.88       892\n",
            "           6       0.96      0.94      0.95       958\n",
            "           7       0.94      0.92      0.93      1028\n",
            "           8       0.94      0.81      0.87       974\n",
            "           9       0.93      0.90      0.91      1009\n",
            "\n",
            "    accuracy                           0.93     10000\n",
            "   macro avg       0.93      0.93      0.93     10000\n",
            "weighted avg       0.93      0.93      0.93     10000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kGeLBs25GLM",
        "colab_type": "text"
      },
      "source": [
        "## CNN for CIFAR-10 Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ocdDhiaJ_mZ_",
        "colab_type": "text"
      },
      "source": [
        "The CIFAR dataset is a complicated dataset with 10 classes of 6000 images in the respective classes. This is complicated in several aspects on of them being the RGB values in the input image. The pixel values without any inofrmation all has a greater pixel values unlike in MNIST dataset. The CIFAR dataset training was complicated because of the nature of the data. Generalisation techniques like Dropouts, Regularisation and Batch Normalisation were tried to achive better results and help the Network genralise better. Several, Networks of different sizes were tried starting with the shallow CNN used in for MNIST case.\n",
        "\n",
        "According to the white paper listed below:\n",
        "> *   https://arxiv.org/pdf/1603.05027.pdf\n",
        "> *   https://keras.io/examples/cifar10_resnet/\n",
        "\n",
        "\n",
        "the ResNets are indetified to perform better for the datasets. The filter sizes are doubled ofr every convoloutional layer as we progress from input layer to the output layer, meanwhile the strides are halved(downsampled). \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_DQqnki5Kkz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "f6088b19-d351-4fc0-94c1-0582a8221102"
      },
      "source": [
        "batch_size = 256  # orig paper trained all networks with batch_size=128\n",
        "epochs = 200\n",
        "data_augmentation = True\n",
        "num_classes = 10\n",
        "\n",
        "subtract_pixel_mean = True\n",
        "\n",
        "n = 3\n",
        "depth = n * 6 + 2\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "input_shape = x_train.shape[1:]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 11s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6o9drIrCDH6E",
        "colab_type": "text"
      },
      "source": [
        "The input data is normalised(the pixel values). By subtarcting the mean of the pixel values help us reach better accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjOj-009DCAV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = x_train.astype('float32') / 255\n",
        "x_test = x_test.astype('float32') / 255\n",
        "\n",
        "if subtract_pixel_mean:\n",
        "    x_train_mean = np.mean(x_train, axis=0)\n",
        "    x_train -= x_train_mean\n",
        "    x_test -= x_train_mean"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9XlzGrkwDuwp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGnESvHob2gR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lr_schedule(epoch):\n",
        "    \"\"\"Learning Rate Schedule\n",
        "\n",
        "    Learning rate is scheduled to be reduced after 80, 120, 160, 180 epochs.\n",
        "    Called automatically every epoch as part of callbacks during training.\n",
        "\n",
        "    # Arguments\n",
        "        epoch (int): The number of epochs\n",
        "\n",
        "    # Returns\n",
        "        lr (float32): learning rate\n",
        "    \"\"\"\n",
        "    lr = 1e-3\n",
        "    if epoch > 180:\n",
        "        lr *= 0.5e-3\n",
        "    elif epoch > 160:\n",
        "        lr *= 1e-3\n",
        "    elif epoch > 120:\n",
        "        lr *= 1e-2\n",
        "    elif epoch > 80:\n",
        "        lr *= 1e-1\n",
        "    print('Learning rate: ', lr)\n",
        "    return lr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJJhLwwRDxHX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def resnet_layer(inputs, num_filters=16, kernel_size=3, strides=1, activation='relu',batch_normalization=True,conv_first=True):\n",
        "    \n",
        "    conv = Conv2D(num_filters,\n",
        "                  kernel_size=kernel_size,\n",
        "                  strides=strides,\n",
        "                  padding='same',\n",
        "                  kernel_initializer='he_normal',\n",
        "                  kernel_regularizer=l2(1e-4))\n",
        "\n",
        "    x = inputs\n",
        "    if conv_first:\n",
        "        x = conv(x)\n",
        "        if batch_normalization:\n",
        "            x = BatchNormalization()(x)\n",
        "        if activation is not None:\n",
        "            x = Activation(activation)(x)\n",
        "    else:\n",
        "        if batch_normalization:\n",
        "            x = BatchNormalization()(x)\n",
        "        if activation is not None:\n",
        "            x = Activation(activation)(x)\n",
        "        x = conv(x)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ejm_ao3zI8p_",
        "colab_type": "text"
      },
      "source": [
        "Here we build the 2D Convoultion layers - Batch Normalisation pairs. The method is taken from the above link and modified to the convinience. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqIpqt8_I8G6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def resnet_v1(input_shape, depth, num_classes=10):\n",
        "    if (depth - 2) % 6 != 0:\n",
        "        raise ValueError('depth should be 6n+2 (eg 20, 32, 44 in [a])')\n",
        "    num_filters = 16\n",
        "    num_res_blocks = int((depth - 2) / 6)\n",
        "\n",
        "    inputs = Input(shape=input_shape)\n",
        "    x = resnet_layer(inputs=inputs)\n",
        "    # Instantiate the stack of residual units\n",
        "    for stack in range(3):\n",
        "        for res_block in range(num_res_blocks):\n",
        "            strides = 1\n",
        "            if stack > 0 and res_block == 0:  # first layer but not first stack\n",
        "                strides = 2  # downsample\n",
        "            y = resnet_layer(inputs=x, num_filters=num_filters,strides=strides)\n",
        "            y = resnet_layer(inputs=y,num_filters=num_filters, activation=None)\n",
        "            if stack > 0 and res_block == 0:  \n",
        "                x = resnet_layer(inputs=x,num_filters=num_filters, kernel_size=1,strides=strides, activation=None, batch_normalization=False)\n",
        "            x = keras.layers.add([x, y])\n",
        "            x = Activation('relu')(x)\n",
        "        num_filters *= 2\n",
        "\n",
        "    # Add classifier on top.\n",
        "    # v1 does not use BN after last shortcut connection-ReLU\n",
        "    x = AveragePooling2D(pool_size=8)(x)\n",
        "    y = Flatten()(x)\n",
        "    outputs = Dense(num_classes,\n",
        "                    activation='softmax',\n",
        "                    kernel_initializer='he_normal')(y)\n",
        "\n",
        "    # Instantiate model.\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7itH5P1LHiB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ac023ff1-0382-4583-b28a-cf9e8f3bb910"
      },
      "source": [
        "model = resnet_v1(input_shape=input_shape, depth=depth)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=lr_schedule(0)),metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learning rate:  0.001\n",
            "Model: \"model_6\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_6 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_106 (Conv2D)             (None, 32, 32, 16)   448         input_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_96 (BatchNo (None, 32, 32, 16)   64          conv2d_106[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_96 (Activation)      (None, 32, 32, 16)   0           batch_normalization_96[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_107 (Conv2D)             (None, 32, 32, 16)   2320        activation_96[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_97 (BatchNo (None, 32, 32, 16)   64          conv2d_107[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_97 (Activation)      (None, 32, 32, 16)   0           batch_normalization_97[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_108 (Conv2D)             (None, 32, 32, 16)   2320        activation_97[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_98 (BatchNo (None, 32, 32, 16)   64          conv2d_108[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_46 (Add)                    (None, 32, 32, 16)   0           activation_96[0][0]              \n",
            "                                                                 batch_normalization_98[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_98 (Activation)      (None, 32, 32, 16)   0           add_46[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_109 (Conv2D)             (None, 32, 32, 16)   2320        activation_98[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_99 (BatchNo (None, 32, 32, 16)   64          conv2d_109[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_99 (Activation)      (None, 32, 32, 16)   0           batch_normalization_99[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_110 (Conv2D)             (None, 32, 32, 16)   2320        activation_99[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_100 (BatchN (None, 32, 32, 16)   64          conv2d_110[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_47 (Add)                    (None, 32, 32, 16)   0           activation_98[0][0]              \n",
            "                                                                 batch_normalization_100[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_100 (Activation)     (None, 32, 32, 16)   0           add_47[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_111 (Conv2D)             (None, 32, 32, 16)   2320        activation_100[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_101 (BatchN (None, 32, 32, 16)   64          conv2d_111[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_101 (Activation)     (None, 32, 32, 16)   0           batch_normalization_101[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_112 (Conv2D)             (None, 32, 32, 16)   2320        activation_101[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_102 (BatchN (None, 32, 32, 16)   64          conv2d_112[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_48 (Add)                    (None, 32, 32, 16)   0           activation_100[0][0]             \n",
            "                                                                 batch_normalization_102[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_102 (Activation)     (None, 32, 32, 16)   0           add_48[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_113 (Conv2D)             (None, 16, 16, 32)   4640        activation_102[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_103 (BatchN (None, 16, 16, 32)   128         conv2d_113[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_103 (Activation)     (None, 16, 16, 32)   0           batch_normalization_103[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_114 (Conv2D)             (None, 16, 16, 32)   9248        activation_103[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_115 (Conv2D)             (None, 16, 16, 32)   544         activation_102[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_104 (BatchN (None, 16, 16, 32)   128         conv2d_114[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_49 (Add)                    (None, 16, 16, 32)   0           conv2d_115[0][0]                 \n",
            "                                                                 batch_normalization_104[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_104 (Activation)     (None, 16, 16, 32)   0           add_49[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_116 (Conv2D)             (None, 16, 16, 32)   9248        activation_104[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_105 (BatchN (None, 16, 16, 32)   128         conv2d_116[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_105 (Activation)     (None, 16, 16, 32)   0           batch_normalization_105[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_117 (Conv2D)             (None, 16, 16, 32)   9248        activation_105[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_106 (BatchN (None, 16, 16, 32)   128         conv2d_117[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_50 (Add)                    (None, 16, 16, 32)   0           activation_104[0][0]             \n",
            "                                                                 batch_normalization_106[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_106 (Activation)     (None, 16, 16, 32)   0           add_50[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_118 (Conv2D)             (None, 16, 16, 32)   9248        activation_106[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_107 (BatchN (None, 16, 16, 32)   128         conv2d_118[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_107 (Activation)     (None, 16, 16, 32)   0           batch_normalization_107[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_119 (Conv2D)             (None, 16, 16, 32)   9248        activation_107[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_108 (BatchN (None, 16, 16, 32)   128         conv2d_119[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_51 (Add)                    (None, 16, 16, 32)   0           activation_106[0][0]             \n",
            "                                                                 batch_normalization_108[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_108 (Activation)     (None, 16, 16, 32)   0           add_51[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_120 (Conv2D)             (None, 8, 8, 64)     18496       activation_108[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_109 (BatchN (None, 8, 8, 64)     256         conv2d_120[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_109 (Activation)     (None, 8, 8, 64)     0           batch_normalization_109[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_121 (Conv2D)             (None, 8, 8, 64)     36928       activation_109[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_122 (Conv2D)             (None, 8, 8, 64)     2112        activation_108[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_110 (BatchN (None, 8, 8, 64)     256         conv2d_121[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_52 (Add)                    (None, 8, 8, 64)     0           conv2d_122[0][0]                 \n",
            "                                                                 batch_normalization_110[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_110 (Activation)     (None, 8, 8, 64)     0           add_52[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_123 (Conv2D)             (None, 8, 8, 64)     36928       activation_110[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_111 (BatchN (None, 8, 8, 64)     256         conv2d_123[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_111 (Activation)     (None, 8, 8, 64)     0           batch_normalization_111[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_124 (Conv2D)             (None, 8, 8, 64)     36928       activation_111[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_112 (BatchN (None, 8, 8, 64)     256         conv2d_124[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_53 (Add)                    (None, 8, 8, 64)     0           activation_110[0][0]             \n",
            "                                                                 batch_normalization_112[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_112 (Activation)     (None, 8, 8, 64)     0           add_53[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_125 (Conv2D)             (None, 8, 8, 64)     36928       activation_112[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_113 (BatchN (None, 8, 8, 64)     256         conv2d_125[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_113 (Activation)     (None, 8, 8, 64)     0           batch_normalization_113[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_126 (Conv2D)             (None, 8, 8, 64)     36928       activation_113[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_114 (BatchN (None, 8, 8, 64)     256         conv2d_126[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_54 (Add)                    (None, 8, 8, 64)     0           activation_112[0][0]             \n",
            "                                                                 batch_normalization_114[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_114 (Activation)     (None, 8, 8, 64)     0           add_54[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 1, 1, 64)     0           activation_114[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "flatten_6 (Flatten)             (None, 64)           0           average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dense_6 (Dense)                 (None, 10)           650         flatten_6[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 274,442\n",
            "Trainable params: 273,066\n",
            "Non-trainable params: 1,376\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8-3CWB4NO69",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Prepare model model saving directory.\n",
        "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
        "model_name = 'cifar10_%s_model.{epoch:03d}.h5'\n",
        "if not os.path.isdir(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "filepath = os.path.join(save_dir, model_name)\n",
        "\n",
        "# Prepare callbacks for model saving and for learning rate adjustment.\n",
        "checkpoint = ModelCheckpoint(filepath=filepath,monitor='val_acc',verbose=1, save_best_only=True)\n",
        "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
        "\n",
        "callbacks = [checkpoint, tensorboard_callback, lr_scheduler]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKjWgEkgOQbm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if not data_augmentation:\n",
        "    print('Not using data augmentation.')\n",
        "    model.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              validation_data=(x_test, y_test),\n",
        "              shuffle=True,\n",
        "              callbacks=callbacks)\n",
        "else:\n",
        "    print('Using real-time data augmentation.')\n",
        "    # This will do preprocessing and realtime data augmentation:\n",
        "    datagen = ImageDataGenerator(\n",
        "        # set input mean to 0 over the dataset\n",
        "        featurewise_center=False,\n",
        "        # set each sample mean to 0\n",
        "        samplewise_center=False,\n",
        "        # divide inputs by std of dataset\n",
        "        featurewise_std_normalization=False,\n",
        "        # divide each input by its std\n",
        "        samplewise_std_normalization=False,\n",
        "        # apply ZCA whitening\n",
        "        zca_whitening=False,\n",
        "        # epsilon for ZCA whitening\n",
        "        zca_epsilon=1e-06,\n",
        "        # randomly rotate images in the range (deg 0 to 180)\n",
        "        rotation_range=0,\n",
        "        # randomly shift images horizontally\n",
        "        width_shift_range=0.1,\n",
        "        # randomly shift images vertically\n",
        "        height_shift_range=0.1,\n",
        "        # set range for random shear\n",
        "        shear_range=0.,\n",
        "        # set range for random zoom\n",
        "        zoom_range=0.,\n",
        "        # set range for random channel shifts\n",
        "        channel_shift_range=0.,\n",
        "        # set mode for filling points outside the input boundaries\n",
        "        fill_mode='nearest',\n",
        "        # value used for fill_mode = \"constant\"\n",
        "        cval=0.,\n",
        "        # randomly flip images\n",
        "        horizontal_flip=True,\n",
        "        # randomly flip images\n",
        "        vertical_flip=False,\n",
        "        # set rescaling factor (applied before any other transformation)\n",
        "        rescale=None,\n",
        "        # set function that will be applied on each input\n",
        "        preprocessing_function=None,\n",
        "        # image data format, either \"channels_first\" or \"channels_last\"\n",
        "        data_format=None,\n",
        "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
        "        validation_split=0.0)\n",
        "\n",
        "    # Compute quantities required for featurewise normalization\n",
        "    # (std, mean, and principal components if ZCA whitening is applied).\n",
        "    datagen.fit(x_train)\n",
        "\n",
        "    # Fit the model on the batches generated by datagen.flow().\n",
        "    model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
        "                        validation_data=(x_test, y_test),\n",
        "                        epochs=epochs, verbose=1, workers=4,\n",
        "                        callbacks=callbacks)\n",
        "\n",
        "# Score trained model.\n",
        "scores = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', scores[0])\n",
        "print('Test accuracy:', scores[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3AEEl3gRORiA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "14eaf034-0176-4f36-e65b-e59d865faa8f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "model1 = keras.models.load_model('/content/drive/My Drive/Colab Notebooks/CNN_resnet.hd5')"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YqK3gG7XSE2r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "feab56ec-78f7-4871-cb80-60dc47b8e402"
      },
      "source": [
        "print(model1.evaluate(x_test, y_test))\n",
        "y_hat_1 = model1.predict(x_test)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 3s 301us/step\n",
            "[0.49906386132240294, 0.9085000157356262]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rflqF_lLSIXC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "outputId": "11fedd43-2f1f-4b6f-8ba0-b04108f02903"
      },
      "source": [
        "print(metrics.classification_report(y_hat_1.argmax(axis=1), np.argmax(y_test, axis=1)))"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.91      0.92      1015\n",
            "           1       0.97      0.95      0.96      1023\n",
            "           2       0.86      0.87      0.87       990\n",
            "           3       0.79      0.82      0.81       960\n",
            "           4       0.92      0.90      0.91      1020\n",
            "           5       0.84      0.87      0.85       966\n",
            "           6       0.95      0.91      0.93      1045\n",
            "           7       0.94      0.95      0.95       987\n",
            "           8       0.95      0.96      0.95       990\n",
            "           9       0.95      0.94      0.94      1004\n",
            "\n",
            "    accuracy                           0.91     10000\n",
            "   macro avg       0.91      0.91      0.91     10000\n",
            "weighted avg       0.91      0.91      0.91     10000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jsiCrbEagw9w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "89555969-3601-4e66-f52e-590aaf924eee"
      },
      "source": [
        "sns.heatmap(metrics.confusion_matrix(y_hat_1.argmax(axis=1), np.argmax(y_test, axis=1)), cmap = 'GnBu', cbar=True)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f9c2e6b79e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pc7Y10afX3Ys",
        "colab_type": "text"
      },
      "source": [
        "On training the NN model with image augmentation and for 200 epoch with varying learning rate. We observe the following behaviour.\n",
        "\n",
        "![alt text](https://drive.google.com/uc?id=1-k3ROZNy8CBjJJupxN5Yp6Wnh4fKSmf_)\n",
        "\n",
        "The plot shows the loss for validation and training against number of epochs.\n",
        "\n",
        "\n",
        "![alt text](https://drive.google.com/uc?id=1-eMnMrI2l9PBcUxeZ0WZYP1-YV4EJmnq)\n",
        "\n",
        "The plot shows the accuracy for the training and validation.\n",
        "\n",
        "![alt text](https://drive.google.com/uc?id=1-e3Qd8kq1G4mOAsJrMkvEwFOo0npHdvg)\n",
        "\n",
        "The figure shows the input image after normalisation and subtacting the pixel mean.\n",
        "\n",
        "![alt text](https://drive.google.com/uc?id=1-Nq03zfZBZ0vsH61-F8wojF1jpxlqwQc)\n",
        "\n",
        "The figure shows the varying learning rate across the epochs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19CNMROw5MFS",
        "colab_type": "text"
      },
      "source": [
        "## CNN for CIFAR-100 Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3y3S5QKk5QBw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 256  # orig paper trained all networks with batch_size=128\n",
        "epochs = 200\n",
        "data_augmentation = True\n",
        "num_classes = 100\n",
        "\n",
        "subtract_pixel_mean = True\n",
        "\n",
        "n = 3\n",
        "depth = n * 6 + 2\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
        "input_shape = x_train.shape[1:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRxSF1MHjw_P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = x_train.astype('float32') / 255\n",
        "x_test = x_test.astype('float32') / 255\n",
        "\n",
        "if subtract_pixel_mean:\n",
        "    x_train_mean = np.mean(x_train, axis=0)\n",
        "    x_train -= x_train_mean\n",
        "    x_test -= x_train_mean\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xEwOjax6kc6P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if version == 2:\n",
        "    model = resnet_v2(input_shape=input_shape, depth=depth)\n",
        "else:\n",
        "    model = resnet_v1(input_shape=input_shape, depth=depth)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(learning_rate=lr_schedule(0)),\n",
        "              metrics=['accuracy'])\n",
        "model.summary()\n",
        "print(model_type)\n",
        "\n",
        "# Prepare model model saving directory.\n",
        "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
        "model_name = 'cifar100_%s_model.{epoch:03d}.h5' % model_type\n",
        "if not os.path.isdir(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "filepath = os.path.join(save_dir, model_name)\n",
        "\n",
        "# Prepare callbacks for model saving and for learning rate adjustment.\n",
        "checkpoint = ModelCheckpoint(filepath=filepath,\n",
        "                             monitor='val_acc',\n",
        "                             verbose=1,\n",
        "                             save_best_only=True)\n",
        "\n",
        "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
        "\n",
        "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n",
        "                               cooldown=0,\n",
        "                               patience=5,\n",
        "                               min_lr=0.5e-6)\n",
        "\n",
        "callbacks = [checkpoint, lr_reducer, lr_scheduler]\n",
        "\n",
        "# Run training, with or without data augmentation.\n",
        "if not data_augmentation:\n",
        "    print('Not using data augmentation.')\n",
        "    model.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              validation_data=(x_test, y_test),\n",
        "              shuffle=True,\n",
        "              callbacks=callbacks)\n",
        "else:\n",
        "    print('Using real-time data augmentation.')\n",
        "    # This will do preprocessing and realtime data augmentation:\n",
        "    datagen = ImageDataGenerator(\n",
        "        # set input mean to 0 over the dataset\n",
        "        featurewise_center=False,\n",
        "        # set each sample mean to 0\n",
        "        samplewise_center=False,\n",
        "        # divide inputs by std of dataset\n",
        "        featurewise_std_normalization=False,\n",
        "        # divide each input by its std\n",
        "        samplewise_std_normalization=False,\n",
        "        # apply ZCA whitening\n",
        "        zca_whitening=False,\n",
        "        # epsilon for ZCA whitening\n",
        "        zca_epsilon=1e-06,\n",
        "        # randomly rotate images in the range (deg 0 to 180)\n",
        "        rotation_range=0,\n",
        "        # randomly shift images horizontally\n",
        "        width_shift_range=0.1,\n",
        "        # randomly shift images vertically\n",
        "        height_shift_range=0.1,\n",
        "        # set range for random shear\n",
        "        shear_range=0.,\n",
        "        # set range for random zoom\n",
        "        zoom_range=0.,\n",
        "        # set range for random channel shifts\n",
        "        channel_shift_range=0.,\n",
        "        # set mode for filling points outside the input boundaries\n",
        "        fill_mode='nearest',\n",
        "        # value used for fill_mode = \"constant\"\n",
        "        cval=0.,\n",
        "        # randomly flip images\n",
        "        horizontal_flip=True,\n",
        "        # randomly flip images\n",
        "        vertical_flip=False,\n",
        "        # set rescaling factor (applied before any other transformation)\n",
        "        rescale=None,\n",
        "        # set function that will be applied on each input\n",
        "        preprocessing_function=None,\n",
        "        # image data format, either \"channels_first\" or \"channels_last\"\n",
        "        data_format=None,\n",
        "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
        "        validation_split=0.0)\n",
        "\n",
        "    # Compute quantities required for featurewise normalization\n",
        "    # (std, mean, and principal components if ZCA whitening is applied).\n",
        "    datagen.fit(x_train)\n",
        "\n",
        "    # Fit the model on the batches generated by datagen.flow().\n",
        "    model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
        "                        validation_data=(x_test, y_test),\n",
        "                        epochs=epochs, verbose=1, workers=4,\n",
        "                        callbacks=callbacks)\n",
        "\n",
        "# Score trained model.\n",
        "scores = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', scores[0])\n",
        "print('Test accuracy:', scores[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5ieM_k-FFWj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_cifar100 = tf.keras.models.load_model('/content/drive/My Drive/Colab Notebooks/CNN_resnet_cifar100_2.hd5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EttawuBXFhKv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "142d4924-d2b1-43ec-bc65-d5249a9c9509"
      },
      "source": [
        "print(model_cifar100.evaluate(x_test, y_test))\n",
        "y_hat_1 = model_cifar100.predict(x_test)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 2s 6ms/step - loss: 1.6738 - accuracy: 0.6284\n",
            "[1.6738015413284302, 0.6284000277519226]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cr65n8SVHGse",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        },
        "outputId": "6ec01d13-f23e-477b-e7c5-d17afd5398f1"
      },
      "source": [
        "sns.heatmap(tf.math.confusion_matrix(np.argmax(y_hat_1, axis=1), np.argmax(y_test, axis=1) ), cmap='GnBu', cbar=True)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f8638cb0e48>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m95C2kwDHP6b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c43962a2-e24c-4471-fb35-fa188e428f36"
      },
      "source": [
        "print(metrics.classification_report(y_hat_1.argmax(axis=1), np.argmax(y_test, axis=1)))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.89      0.80        81\n",
            "           1       0.73      0.80      0.76        91\n",
            "           2       0.52      0.58      0.55        89\n",
            "           3       0.36      0.55      0.43        66\n",
            "           4       0.43      0.51      0.47        84\n",
            "           5       0.63      0.69      0.66        91\n",
            "           6       0.71      0.66      0.69       107\n",
            "           7       0.65      0.55      0.59       119\n",
            "           8       0.82      0.71      0.76       115\n",
            "           9       0.73      0.85      0.78        86\n",
            "          10       0.43      0.43      0.43       101\n",
            "          11       0.45      0.45      0.45       101\n",
            "          12       0.75      0.61      0.67       123\n",
            "          13       0.54      0.57      0.56        94\n",
            "          14       0.60      0.47      0.53       127\n",
            "          15       0.67      0.66      0.67       101\n",
            "          16       0.68      0.65      0.66       105\n",
            "          17       0.74      0.81      0.77        91\n",
            "          18       0.53      0.49      0.51       109\n",
            "          19       0.61      0.64      0.62        96\n",
            "          20       0.84      0.83      0.84       101\n",
            "          21       0.78      0.84      0.81        93\n",
            "          22       0.64      0.59      0.62       108\n",
            "          23       0.66      0.79      0.72        84\n",
            "          24       0.79      0.82      0.81        96\n",
            "          25       0.58      0.54      0.56       107\n",
            "          26       0.63      0.42      0.51       149\n",
            "          27       0.50      0.49      0.50       102\n",
            "          28       0.76      0.71      0.73       107\n",
            "          29       0.54      0.62      0.58        87\n",
            "          30       0.55      0.67      0.60        82\n",
            "          31       0.50      0.72      0.59        69\n",
            "          32       0.58      0.58      0.58       100\n",
            "          33       0.61      0.57      0.59       107\n",
            "          34       0.66      0.67      0.66        99\n",
            "          35       0.33      0.42      0.37        78\n",
            "          36       0.70      0.85      0.77        82\n",
            "          37       0.69      0.67      0.68       103\n",
            "          38       0.47      0.53      0.50        88\n",
            "          39       0.77      0.73      0.75       106\n",
            "          40       0.58      0.57      0.58       101\n",
            "          41       0.81      0.75      0.78       108\n",
            "          42       0.77      0.42      0.54       184\n",
            "          43       0.56      0.77      0.65        73\n",
            "          44       0.36      0.32      0.34       111\n",
            "          45       0.56      0.46      0.50       122\n",
            "          46       0.43      0.40      0.41       108\n",
            "          47       0.56      0.57      0.56        99\n",
            "          48       0.89      0.76      0.82       117\n",
            "          49       0.81      0.74      0.78       109\n",
            "          50       0.41      0.38      0.39       109\n",
            "          51       0.70      0.62      0.66       113\n",
            "          52       0.70      0.56      0.62       125\n",
            "          53       0.88      0.77      0.82       114\n",
            "          54       0.76      0.72      0.74       105\n",
            "          55       0.25      0.32      0.28        77\n",
            "          56       0.78      0.90      0.83        87\n",
            "          57       0.63      0.73      0.68        86\n",
            "          58       0.76      0.80      0.78        95\n",
            "          59       0.55      0.59      0.57        93\n",
            "          60       0.79      0.84      0.81        94\n",
            "          61       0.65      0.68      0.67        95\n",
            "          62       0.66      0.66      0.66       100\n",
            "          63       0.63      0.54      0.58       116\n",
            "          64       0.38      0.55      0.45        69\n",
            "          65       0.51      0.58      0.54        88\n",
            "          66       0.68      0.59      0.63       116\n",
            "          67       0.44      0.54      0.49        81\n",
            "          68       0.86      0.93      0.90        92\n",
            "          69       0.73      0.77      0.75        95\n",
            "          70       0.67      0.71      0.69        95\n",
            "          71       0.67      0.74      0.71        90\n",
            "          72       0.32      0.36      0.34        89\n",
            "          73       0.40      0.48      0.44        83\n",
            "          74       0.44      0.37      0.40       119\n",
            "          75       0.81      0.75      0.78       108\n",
            "          76       0.82      0.86      0.84        95\n",
            "          77       0.52      0.63      0.57        82\n",
            "          78       0.52      0.37      0.44       139\n",
            "          79       0.74      0.69      0.71       107\n",
            "          80       0.36      0.53      0.43        68\n",
            "          81       0.74      0.63      0.68       117\n",
            "          82       0.83      0.86      0.85        96\n",
            "          83       0.58      0.63      0.60        92\n",
            "          84       0.62      0.65      0.63        96\n",
            "          85       0.78      0.79      0.78        99\n",
            "          86       0.71      0.60      0.65       119\n",
            "          87       0.73      0.62      0.67       118\n",
            "          88       0.71      0.70      0.70       102\n",
            "          89       0.75      0.68      0.71       111\n",
            "          90       0.74      0.68      0.71       109\n",
            "          91       0.67      0.70      0.68        96\n",
            "          92       0.50      0.68      0.58        73\n",
            "          93       0.51      0.48      0.49       107\n",
            "          94       0.87      0.86      0.87       101\n",
            "          95       0.63      0.61      0.62       103\n",
            "          96       0.47      0.55      0.51        86\n",
            "          97       0.71      0.72      0.71        99\n",
            "          98       0.43      0.43      0.43        99\n",
            "          99       0.63      0.66      0.65        95\n",
            "\n",
            "    accuracy                           0.63     10000\n",
            "   macro avg       0.63      0.64      0.63     10000\n",
            "weighted avg       0.64      0.63      0.63     10000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6dIpodjKHlcm",
        "colab_type": "text"
      },
      "source": [
        "The plot shows the loss for validation and training against number of epochs.\n",
        "\n",
        "![alt text](https://drive.google.com/uc?id=1-t_oVS2ogocEas-vb_YyAo-C8N63aGNm)\n",
        "\n",
        "The plot shows the accuracy for the training and validation.\n",
        "\n",
        "![alt text](https://drive.google.com/uc?id=102-wDCf4fOLKXu6V8PbX1oD-wGdYs3av)\n",
        "\n",
        "The figure shows the varying learning rate across the epochs.\n",
        "![alt text](https://drive.google.com/uc?id=108UaqSKdTkoLLbt9r1_044KHJzNB1H6D)\n",
        "\n",
        "The figure shows the input image after normalisation and subtacting the pixel mean.\n",
        "\n",
        "![alt text](https://drive.google.com/uc?id=103bKsq8Xw0zVBNIE6FZFTPOyUcnmRIQS)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMSv6ls6Iz3b",
        "colab_type": "text"
      },
      "source": [
        "The model is the same as the above except for the last layer. The model was trained for 150 epochs. As the learning curves indicate, the model is still capable of learning and is not yet overfitting or underfitting. It can be trained further with number of epochs to achieve better results. The model still needs to fine tuned for the best results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7C7jnwnRSDqB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorboard --logdir logs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DvZ334q2_FH_",
        "colab_type": "text"
      },
      "source": [
        "## References:\n",
        "\n",
        "$ @TECHREPORT { Krizhevsky09learningmultiple, author = {Alex Krizhevsky},\n",
        "    title = {Learning multiple layers of features from tiny images},\n",
        "    institution = {},\n",
        "    year = {2009}} $"
      ]
    }
  ]
}